# URL-TO-YOUR-WEAVIATE-CLUSTER
WEAVIATE_URL_VERBA=

# API-KEY-OF-YOUR-WEAVIATE-CLUSTER
WEAVIATE_API_KEY_VERBA=

# YOUR-OPENAI-KEY
OPENAI_API_KEY=

# YOUR-COHERE-KEY
COHERE_API_KEY=

# YOUR-UNSTRUCTURED-KEY
UNSTRUCTURED_API_KEY=

# YOUR-GITHUB-TOKEN
GITHUB_TOKEN=

# YOUR-HUGGINGFACE-TOKEN
HF_TOKEN=

# ENABLE-LLAMA2?-(True or False)
LLAMA2-7B-CHAT-HF=

# Optional parameters when using azure OpenAI. 

# set type, should be "azure".
#OPENAI_API_TYPE="azure"

# resource name is the first part of your endpoint. 
# for example if your endpoint is XXX.openai.azure.com, it is XXX
#AZURE_OPENAI_RESOURCE_NAME=

# model used for embeddings
#AZURE_OPENAI_EMBEDDING_MODEL="text-embedding-ada-002"

# your azure openai endpoint. should be https://XXX.openai.azure.com
#OPENAI_API_BASE=

# your azure openai key
#OPENAI_API_KEY=

# your azure openai model delpoyment. typically gpt-4
#OPENAI_MODEL="gpt-4"

# waiting time  between queries, in ms. this is required if you have per minute quota, 
# which is usual with Azure OpenAI
# for example, if you have a limit of 240k tokens per minute, if your chunks are 
# 400 tokens max, then 100ms between queries should be fine
# if you get error 429 from weaviate, then increase this value.
#WAIT_TIME_BETWEEN_INGESTION_QUERIES_MS="100"

